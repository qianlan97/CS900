# -*- coding: utf-8 -*-
"""resnet18.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ovVfnuBE6N9bF3rVsqAqUiEteSaKkcya
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import random
from tqdm import tqdm
import time
import os

import torch
import torchvision
import time
from torch import nn
import torchvision.transforms as transforms
from torchvision.models import resnet18
from torch.utils import data
from torch.utils.data import DataLoader
from torchsummary import summary
from PIL import Image

# import matplotlib.pyplot as plt
# # %matplotlib inline

seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"running on {device}")

start_time = time.time()

"""Load the data"""

# transforms.Resize(size):将图片的短边缩放成size的比例，然后长边也跟着缩放，使得缩放后的图片相对于原图的长宽比不变
# transforms.CenterCrop(size):从图像的中心位置裁剪指定大小的图像
# ToTensor():将图像由PIL转换为Tensor
# transform.Normalize():把0-1变换到(-1,1)
# image = (image - mean) / std
# 其中mean和std分别通过(0.5, 0.5, 0.5)和(0.2, 0.2, 0.2)进行指定。原来的0-1最小值0则变成(0-0.5)/0.5=-1，而最大值1则变成(1-0.5)/0.5=1
trans = transforms.Compose([
    # transforms.Resize(224),
    # transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5),(0.2, 0.2, 0.2))
])

# data_transform=torchvision.transforms.ToTensor()

# train_set=torchvision.datasets.CIFAR10(root="./dataset",train=True,download=True,transform=trans)
# # train_dataset=data.DataLoader(train_set,batch_size=64,shuffle=True)

# train_dataset=data.DataLoader(train_set,batch_size=2,shuffle=False)  # train a single image to compare gradient

# Load the test image
train_image_path = "./single-image/cifar10_test_image.png"
train_image = Image.open(train_image_path)
# Apply transformations to the test image
train_image = trans(train_image)
train_image = train_image.unsqueeze(0)
train_labels = torch.Tensor([0]).float()

"""Building Resnet 18 Model from scratch (if needed)"""

# import torch.nn.functional as F

# class BasicBlock(nn.Module):
#     expansion = 1


#     def __init__(self, in_planes, planes, stride=1):
#         super(BasicBlock, self).__init__()

#         DROPOUT = 0.1

#         self.conv1 = nn.Conv2d(
#             in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(planes)
#         self.dropout = nn.Dropout(DROPOUT)
#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
#                                stride=1, padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(planes)
#         self.dropout = nn.Dropout(DROPOUT)

#         self.shortcut = nn.Sequential()
#         if stride != 1 or in_planes != self.expansion*planes:
#             self.shortcut = nn.Sequential(
#                 nn.Conv2d(in_planes, self.expansion*planes,
#                           kernel_size=1, stride=stride, bias=False),
#                 nn.BatchNorm2d(self.expansion*planes),
#                 nn.Dropout(DROPOUT)
#             )

#     def forward(self, x):
#         out = F.relu(self.dropout(self.bn1(self.conv1(x))))
#         out = self.dropout(self.bn2(self.conv2(out)))
#         out += self.shortcut(x)
#         out = F.relu(out)
#         return out


# class ResNet(nn.Module):
#     def __init__(self, block, num_blocks, num_classes=10):
#         super(ResNet, self).__init__()
#         self.in_planes = 64

#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3,
#                                stride=1, padding=1, bias=False)
#         self.bn1 = nn.BatchNorm2d(64)
#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
#         self.linear = nn.Linear(512*block.expansion, num_classes)

#     def _make_layer(self, block, planes, num_blocks, stride):
#         strides = [stride] + [1]*(num_blocks-1)
#         layers = []
#         for stride in strides:
#             layers.append(block(self.in_planes, planes, stride))
#             self.in_planes = planes * block.expansion
#         return nn.Sequential(*layers)

#     def forward(self, x):
#         out = F.relu(self.bn1(self.conv1(x)))
#         out = self.layer1(out)
#         out = self.layer2(out)
#         out = self.layer3(out)
#         out = self.layer4(out)
#         out = F.avg_pool2d(out, 4)
#         out = out.view(out.size(0), -1)
#         out = self.linear(out)
#         return F.log_softmax(out, dim=-1)


# def ResNet18():
#     return ResNet(BasicBlock, [2, 2, 2, 2])


# # Importing Model and printing Summary
# model = ResNet18().to(device)
# summary(model, input_size=(3,32,32))

# model=torchvision.models.resnet18(pretrained=True)
model = torch.load("resnet18-pretrained.pt")
model.to(device) ## deploy the model to the GPU

summary(model, input_size=(3,32,32))

## Replace the last fully connected layer 'fc' of the prebuild model with a new 'nn.linear' layer which has
## 'num_features' as the input size and 10 as the output size.
num_features=model.fc.in_features
model.fc=nn.Linear(num_features,10)
model=model.to(device)
# classes = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

# optimizer1=torch.optim.Adam(model.parameters(),lr=0.0)          ## SGD more likely to get optimal. Adam converge faster
loss=nn.CrossEntropyLoss().to(device, dtype=torch.float)

gradient_dict = {}
output_file = open("result.txt", "w")

for epoch in range(1):
    losssum=0.0
    total=0
    accuracy=0.0

    model.eval()
    model.zero_grad()
    # optimizer1.zero_grad()
    output = model.forward(train_image.to(device))
    lossnum=loss(output,train_labels.to(device, dtype=torch.long))
    lossnum.backward()
    # optimizer1.step()
    # lossnum = loss(output, train_labels.to(device))
    # losssum += lossnum
    # accuracy += (output.argmax(1) == train_labels.to(device)).sum().item()


    # for i,(images,labels) in tqdm(enumerate(train_dataset)):
    # for images,labels in tqdm(train_dataset):
    #     imgs=images.to(device)
    #     labels=labels.to(device)

    #     optimizer1.zero_grad()                          ## clear gradient
    #     output=model.forward(imgs)                      ## predict
    #     lossnum=loss(output,labels)                     ## nn.CrossEntropyLoss()
    #     lossnum.backward()                              ## backpropagation
    #     optimizer1.step()                               ## update parameters using gradients(using SGD defined above)
    #     losssum=losssum+lossnum
    #     accuracy+=(output.argmax(1)==labels).sum()      ## count number of correct predictions by argmax()
    #     break
    # print("Epoch: {}'s accuracy is {}".format(epoch+1, accuracy/len(train_set)))

    # Save gradients for each parameter
    # for name, param in model.named_parameters():
    #     if param.grad is not None:
    #         output_file.write(f"Gradient for {name}: {param.grad}\n")
    #         # print("name:", param.grad.detach().cpu().clone())

    for name, param in model.named_parameters():
        if param.grad is not None:
            if name not in gradient_dict:
                gradient_dict[name] = []
            gradient_dict[name].append(param.grad.detach().cpu().clone())
    print("Saving gradients of epoch", epoch+1)
    torch.save(gradient_dict, 'gradients.pt')

torch.save(model, 'resnet18-posttrained.pt')
print("--- %s seconds ---" % (time.time() - start_time))